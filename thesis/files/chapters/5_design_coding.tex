\chapter{Progettazione e codifica}
\label{cap:progettazione-codifica}

\emph{Breve introduzione al capitolo}

\section{Introduzione}

Partendo da quella che è la richiesta dell'azienda ospitante (catalogazione ed elaborazione delle mail e dei documenti allegati), ho individuato diverse fasi per il processo di elaborazione dei documenti dalle email: 
\begin{itemize}
  \item Estrazione degli allegati presenti in un'email
  \item Classificazione dei documenti
  \item Estrazione delle informazioni importanti dai documenti
  \item  Revisione e valutazione umana delle informazioni estratte
  \item Persistenza dei dati
\end{itemize}

\section{Estrazione degli allegati}
\label{sec:estrazione-allegati}
In questa fase ,le indicazioni iniziali dell'azienda consistevano nell'analizzare il contenuto delle eventuali  email ,per poi effettuarne una classificazione basata sull'elaborazione del linguaggio naturale e dei metadati contenuti. Tuttavia, con il chiarimnento delle categorie prese in analisi durante lo stage ( ordini, fatture e contratti) , ho scelto di concentrarmi sull'estrazione degli allegati presenti nelle stessa piuttosto che sul contenuto della email. 
Tale visione è supportata dal fatto che i documenti di interesse per l'azienda sono spesso allegati delle mail, quindi  tale estrazione determina un flusso di lavoro più chiaro e diretto, oltre al fatto che spesso il contenuto della mail non è rilevante o lo è solo in parte.
Dunque, in questa fase il file di input è un file .eml , mentre l'output sono gli allegati presenti nella mail. Per progettare tutto ciò, ho pensato ai seguenti servizi:
\begin{itemize}
    \item Un \glsfirstoccur{\gls{bucketg}} contenente i file .eml da analizzare
    \item Un \gls{bucketg} contente gli allegati estratti dalle mail 
    \item Una funzione lambda che viene attivata dall'inserimento di un file .eml all'interno del \gls{bucketg} di input e che elabora tale file per ottenere degli allegati di output
\end{itemize}

\section{Classificazione dei documenti}
\label{sec:classificazione-documenti}
Dovendo classificare le email in base al loro contenuto, ho analizzato diverse strade possibili , come quella di utilizzare modelli di \gls{mlg} proposti da Sagemaker per classificare le email. Tuttavia, con il chiarimento delle categorie prese in analisi durante lo stage ( ordini, fatture e contratti) , ho scelto di concentrarmi sull'estrazione degli allegati presenti nelle stessa piuttosto che sul contenuto della email. Questo cambio di prospettiva ha portato a una semplificazione del processo di classificazione, in quanto i metadati (denominati anche features nel campo del machine learning) si riducono al semplice testo estratto dagli allegati. Dunque, per poter classificare un documento in una delle categorie di interesse, ho pensato di utilizzare un modello di machine learning che prendesse in input il testo estratto e restituisse la categoria di appartenenza. In questo senso ,l'utilizzo di strumenti come Textract e Comprehend di \gls{awsg} si è rivelato molto utile, in quanto permette di estrarre il testo dai documenti e di analizzarlo per ottenere informazioni utili. Tuttavia, c'è anche da sottolineare come in una fase iniziale si sia dibattuto riguardo l'utilizzo al loro posto del servizio Bedrock con claude-3. Tale servizio è stato poi scartato a favore di un modello customizzato e maggiormente adatto alla soluzione. 
 In questa fase è necessario distinguire due tipi di flusso di lavoro:
\begin{itemize}
    \item Flusso di lavoro per il training del modello
    \item Flusso di lavoro per la classificazione 
\end{itemize}
\subsection{Flusso di lavoro per il training del modello}
\label{subsec:training-modello}
In questa fase per poter addestrare un modello di Comprehend è necessario disporre di un dataset ampio ,significativo e bilanciato per poter distingure le categorie di interesse. Inoltre, è necessario disporre di un dataset etichettato, in cui ogni documento è associato alla sua categoria di appartenenza. Durante la fase di etichettatatura, sono emerse delle considerazioni importanti. Inanzitutto, i file da analizzare sono per lo piu file pdf (di documenti scansionati o meno), per tale motivo per la fase di training sono stati utilizzati unicamente file con tale estensione. Inoltre, si è scelto, in accordo con il tutor aziendale ,di utilizzare per il training unicamente le prime pagine di tali documenti per diversi motivi : spesso le prime pagine contengono le informazioni più importanti e rilevanti per la classificazione, inoltre, il costo di analizzare un documento è proporzionale al numero di pagine, quindi riducendo il numero di pagine si riducono i costi, assumendo anche il fatto che rispetto ai documenti incontrati il numero di pagine variava fino a 100 pagine. Queste due scelte (utilizzo di file pdf e utilizzo delle prime pagine) hanno portato a una riduzione della varietà dei dati e quindi a una riduzione della capacità del modello di generalizzare su nuovi dati ,creando dei potenziali \glsfirstoccur{\gls{biasg}} nel modello. Di seguito vengono riportati i dati e il loro numero per trainare la prima versione del modello
% da modificare
\begin{itemize}
    \item 100 documenti per la categoria ordini
    \item 100 documenti per la categoria fatture
    \item 100 documenti per la categoria contratti
    \item 100 documenti per la categoria non classificato
\end{itemize}
Per il processo chiamato \glsfirstoccur{\gls{activelearningg}} è stato scelto l'utilizzo di un servizio incluso in Comprehend introdotto recentemente da aws chiamato flywheel.
Tale processo segue i seguenti passi:
\begin{itemize}
    \item Viene creato un dataset flywheel
    \item Viene inizializzata un'iterazione flywheel
    \item In base ai risultati dell'iterazione viene scelto se attivare il nuovo modello formatosi in base a parametri scelti in precedenza
\end{itemize}
\subsubsection{Analisi del dataset}
Percentuale di oridine, fattura, contratti e non classificato 
\subsubsection{Preprocessing}
\begin{itemize}
    \item Estrazione del testo tramite Amazon Textract 
    \item Creazione del file csv 
    \item Caricamento del file di training csv trmite flywheel 
\end{itemize}
\subsubsection{Training}
\begin{itemize}
    \item Creazione di una versione del classificatore su Custom Classifier 
\end{itemize}
\subsubsection{Valutazione}
\subsubsection{Test del modello}
\subsection{Flusso di lavoro per la classificazione}
\label{subsec:classificazione}
Per tale fase, ho scelto di utilizzare i seguenti servizi:
\begin{itemize}
    \item una funzione lambda che riceve in input un'allegato di qualsiasi tipo e (in base se è un pdf o meno) fa partire il processo di classificazione mediate il modello attivo di comprehend
    \item un modello attivo di comprehend che utilizza le funzionalità di textract per estrarre il testo in chiaro dal pdf ricevuto in input e restituisce la categoria di appartenenza con un certa confidenza
    \item tramite un'ulteriore funzione lambda viene analizzata la confidenza e in base a questo viene scelto se salvare l'allegato in un \gls{bucketg} che contiene gli allegati non classificati oppure in un \gls{bucketg} con alto grado di confidenza
\end{itemize}

\section{Estrazione delle informazioni}
In questa fase l'obiettivo è l'estrazione delle informazioni associate a ciascuna categoria escludendo la categoria non classificato. A partire dai risultati di classificazione della fase precedente si è analizzato il metodo migliore per poter estrarre le informazioni ricercate dalle categorie di contratti, ordini e fatture. \\
Fondamentalmente sono stati analizzati diversi metodi utilizzando differenti servizi per aderire a tale scopo:
\begin{itemize}
    \item Comprehend custom entities
    \item Amazon Bedrock
    \item features di textract
\end{itemize}
Digressione sui vantaggi e svantaggi ... 
Alla fine si è optato per le seguenti opzioni:
\begin{itemize}
    \item Custom queries per le fatture 
    \item Custom queries per gli ordini 
    \item Analisi delle tabelle e dei form per i contratti 
\end{itemize}
C'è da sottolineare che per ogni informazione estratta viene anche riportata la percentuale di confidenza.
Il flusso per ogni categoria è il seguente:
\begin{itemize}
    \item Quando un file viene caricato nel bucket relativo ai documenti classificati tale azione scatena l'esecuzione di una lambda apposita per il tipo di documento 
    \item Al termine dell'esecuzione tali informazioni estratte vengono passate alla fase successiva 
\end{itemize}
\subsection{Estrazioni delle informazioni dai contratti}
Per tale fase essendo i contratti della stessa forma, (una tabella con le seguenti informazioni ...) si è optato per un'opzione poco costosa ma comunque efficiace. Tale soluzione consiste nell'identificare tale tabella ed estrarne i campi in base alla conoscenze note. 
\subsection{Estrazione delle informazioni dalle fatture e degli ordini}
Per tale fase si è pensato all'utilizzo di custom queries (adapter) di textract dato che tali documenti possiedono una struttura variabile. L'utilizzo di analisi delle fatture tramite la funzione apposita di textract è stata considerata ma poi scartata. Per gli ordini invece si è pensato di utilizzarla per ricavarne gli articoli in modo piu' diretto e sicuro. 
\section{Persistenza dei dati}
In questa fase l'obiettivo è far persistere i dati. La scelta è ricaduta su Amazon DynamoDB. Il flusso è il seguente:
\begin{itemize}
    \item Per ogni categoria (contratti, ordini, fatture) è creata una lambda, tale lambda salva i risultati delle informazioni estratte in DynamoDB nelle tabelle Ordini, Contratti, Fattura, Articoli\_Fatture, Articoli\_Ordini
\end{itemize}

\section{Analisi dei costi}
%\section{Tecnologie e strumenti}
%\label{sec:tecnologie-strumenti}
%
%Di seguito viene data una panoramica delle tecnologie e strumenti utilizzati.
%
%\subsection*{Tecnologia 1}
%Descrizione Tecnologia 1.
%
%\subsection*{Tecnologia 2}
%Descrizione Tecnologia 2
%
%\section{Ciclo di vita del software}
%\label{sec:ciclo-vita-software}
%
%\section{Progettazione}
%\label{sec:progettazione}
%
%\subsection{Namespace 1} %**************************
%Descrizione namespace 1.
%
%\begin{namespacedesc}
%    \classdesc{Classe 1}{Descrizione classe 1}
%    \classdesc{Classe 2}{Descrizione classe 2}
%\end{namespacedesc}
%
%
%\section{Design Pattern utilizzati}
%
%\section{Codifica}
